# Complete Configuration Example - Google Gemini

# Service configuration
service_name: general-purpose-chatbot
version: 1.0.0
environment: production

# Server configuration
port: 8080
request_timeout: 30s
idle_timeout: 60s

# LLM Provider selection
llm:
  provider: gemini  # claude, gemini, or openai

# Gemini configuration
# Note: api_key should be set via GEMINI_API_KEY environment variable
gemini:
  model: gemini-2.5-flash
  # Optional: for Vertex AI (set via GOOGLE_CLOUD_PROJECT and GOOGLE_CLOUD_REGION env vars)

# Slack configuration
# Note: tokens should be set via SLACK_BOT_TOKEN and SLACK_APP_TOKEN environment variables
slack:
  debug: false

# Telegram configuration
# Note: bot_token should be set via TELEGRAM_BOT_TOKEN environment variable
telegram:
  debug: false

# Session storage
storage:
  backend: local  # local or s3
  local_dir: ./data

# MCP (Model Context Protocol) configuration
mcp:
  enabled: true
  timeout: 30s
  servers:
    filesystem:
      name: filesystem
      enabled: true
      transport: stdio
      command: npx
      args:
        - "-y"
        - "@modelcontextprotocol/server-filesystem"
        - "/data"

# Logging configuration
logging:
  level: info  # debug, info, warn, error
  format: json  # json or text

# Monitoring configuration
monitoring:
  health_check_timeout: 10s

# Security configuration
security:
  cors_allowed_origins:
    - http://localhost:3000
    - http://localhost:8080
  max_request_size: 10485760  # 10MB
  rate_limit_enabled: true
  rate_limit_rps: 100